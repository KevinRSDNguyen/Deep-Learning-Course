{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6XzBe78DGaaQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sjFnsbeIGgNt"
      },
      "outputs": [],
      "source": [
        "features = 2 # E.G. ['breathing_rate', 'blood_pressure']\n",
        "hidden_size = 3  # Hidden State size.\n",
        "batch_size = 1 # E.G. One Person.\n",
        "time_steps = 24 # E.G. 24 hours, capture health data ['heart_rate', 'blood_pressure'] every hour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qOMkAvPIGjj1"
      },
      "outputs": [],
      "source": [
        "rnn = nn.RNN(input_size = features, hidden_size = hidden_size, batch_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic1xNVuAGmyu"
      },
      "source": [
        "`batch_first=True` --> Input shape will be `(batch_size, time_steps, features)`\n",
        "\n",
        "**Ordered data can be stored as a Rank 3 tensor**\n",
        "\n",
        "For example:\n",
        "\n",
        "Every hour, measure `features = 2`, such as `['breathing_rate', 'blood_pressure']`.\n",
        "\n",
        "A day (24 hours) of measurements --> Rank 2 tensor, Shape `[24, 2]`.\n",
        "\n",
        "30 people's measurements         --> Rank 3 tensor, Shape `[30, 24, 2]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yiOSZ1DGkt2",
        "outputId": "aa09271d-59ce-492b-9e72-9096bd572534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1.0000, 0.6203],\n",
            "         [0.7011, 0.7608],\n",
            "         [0.2176, 0.0631],\n",
            "         [0.3910, 0.2742],\n",
            "         [0.9379, 0.4096],\n",
            "         [0.1392, 0.7074],\n",
            "         [0.5251, 0.0778],\n",
            "         [0.3939, 0.0132],\n",
            "         [0.6146, 0.1024],\n",
            "         [0.7200, 0.3159],\n",
            "         [0.0527, 0.2098],\n",
            "         [0.8207, 0.7207],\n",
            "         [0.3945, 0.6380],\n",
            "         [0.4052, 0.7231],\n",
            "         [0.0221, 0.5145],\n",
            "         [0.7611, 0.3566],\n",
            "         [0.3306, 0.5538],\n",
            "         [0.8841, 0.5581],\n",
            "         [0.1950, 0.9009],\n",
            "         [0.9906, 0.9472],\n",
            "         [0.0075, 0.0713],\n",
            "         [0.9093, 0.2202],\n",
            "         [0.5476, 0.3340],\n",
            "         [0.5686, 0.2868]]])\n"
          ]
        }
      ],
      "source": [
        "example_ordered_data = torch.rand(batch_size, time_steps, features)\n",
        "print(example_ordered_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHLpOjGMGuL3",
        "outputId": "97bd1229-5cf9-458b-bca8-4b04a9a7e381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 24, 2])\n"
          ]
        }
      ],
      "source": [
        "print(example_ordered_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HYxGCljeGw0M"
      },
      "outputs": [],
      "source": [
        "history_hidden_states, final_hidden_state = rnn(example_ordered_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1eMZZh6GyIq",
        "outputId": "943d9bd6-8a28-4d9b-fa65-4bc53c75975d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "history_hidden_states: \n",
            " tensor([[[ 0.5006,  0.4074,  0.1494],\n",
            "         [ 0.3066,  0.2466, -0.0606],\n",
            "         [ 0.2871, -0.0355,  0.2916],\n",
            "         [ 0.2837, -0.0808,  0.2586],\n",
            "         [ 0.4883,  0.1033,  0.1814],\n",
            "         [ 0.1880, -0.0330, -0.0364],\n",
            "         [ 0.4516,  0.0058,  0.3135],\n",
            "         [ 0.3235, -0.2461,  0.3154],\n",
            "         [ 0.4466, -0.1847,  0.3074],\n",
            "         [ 0.4723, -0.1261,  0.1642],\n",
            "         [ 0.2886, -0.2970,  0.1849],\n",
            "         [ 0.5156,  0.1100,  0.0040],\n",
            "         [ 0.3674,  0.0330, -0.0579],\n",
            "         [ 0.3805,  0.1295, -0.0550],\n",
            "         [ 0.2257, -0.0163,  0.0512],\n",
            "         [ 0.4772,  0.1343,  0.1915],\n",
            "         [ 0.2595, -0.0196,  0.0426],\n",
            "         [ 0.5101,  0.2169,  0.0801],\n",
            "         [ 0.1978,  0.1006, -0.1514],\n",
            "         [ 0.5309,  0.4648, -0.1137],\n",
            "         [ 0.2020, -0.1184,  0.2055],\n",
            "         [ 0.5071,  0.0708,  0.2853],\n",
            "         [ 0.3519, -0.0976,  0.1462],\n",
            "         [ 0.4366, -0.0602,  0.1896]]], grad_fn=<TransposeBackward1>)\n"
          ]
        }
      ],
      "source": [
        "print('history_hidden_states: \\n', history_hidden_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikLw5bjjGzbY",
        "outputId": "be0ff05f-0ea3-4174-d37e-992d92a9cd46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final_hidden_state: \n",
            " tensor([[[ 0.4366, -0.0602,  0.1896]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print('final_hidden_state: \\n', final_hidden_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBevs4BiG3rH"
      },
      "source": [
        "**For learning purposes, let's calculate the hidden state after the first time step manually.**\n",
        "\n",
        "There will be:\n",
        "1.   Input Weights.\n",
        "2.   Hidden State Weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vRk_eRiG03m",
        "outputId": "d4f5f4c1-395c-45b0-9d3b-f1ee09b5e745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weight_ih_l0\n",
            "weight_hh_l0\n",
            "bias_ih_l0\n",
            "bias_hh_l0\n"
          ]
        }
      ],
      "source": [
        "for name, _ in rnn.named_parameters():\n",
        "    if 'weight' or 'bias' in name:\n",
        "        print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kHPZ-VC7G6ES"
      },
      "outputs": [],
      "source": [
        "input_weights = rnn.weight_ih_l0\n",
        "input_biases = rnn.bias_ih_l0\n",
        "\n",
        "hidden_state_weights = rnn.weight_hh_l0\n",
        "hidden_state_biases = rnn.bias_hh_l0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vRbihPsHGmm"
      },
      "source": [
        "**Current Hidden State =  Activation Function ( (Hidden State Weights * Past Hidden State) + (Input Weights * Current Input) )**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ACykRrAG7uJ",
        "outputId": "79d0c1ce-910c-4d8e-b6fd-4f88104a451c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial hidden state tensor([[0., 0., 0.]])\n",
            "hidden_state_custom after the first time step : tensor([[0.5006, 0.4074, 0.1494]])\n",
            "Hidden state after the first time step: tensor([[0.5006, 0.4074, 0.1494]])\n"
          ]
        }
      ],
      "source": [
        "# Initial hidden state will be zeros.\n",
        "hidden_state_custom = torch.zeros((batch_size, hidden_size))\n",
        "print('Initial hidden state', hidden_state_custom.detach())\n",
        "\n",
        "# (Hidden State Weights * Past Hidden State)\n",
        "hidden_to_hidden = torch.matmul(hidden_state_custom, torch.t(hidden_state_weights)) + hidden_state_biases\n",
        "\n",
        "# (Input Weights * Current Input)\n",
        "current_input = example_ordered_data[:, 0]\n",
        "input_to_hidden = torch.matmul(current_input, torch.t(input_weights)) + input_biases\n",
        "\n",
        "# Current Hidden State = Activation Function ( (Hidden State Weights * Past Hidden State) + (Input Weights * Current Input) )\n",
        "hidden_state_custom = torch.tanh(hidden_to_hidden + input_to_hidden)\n",
        "\n",
        "print('hidden_state_custom after the first time step :', hidden_state_custom.detach())\n",
        "print('Hidden state after the first time step:', history_hidden_states[:, 0].detach())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
